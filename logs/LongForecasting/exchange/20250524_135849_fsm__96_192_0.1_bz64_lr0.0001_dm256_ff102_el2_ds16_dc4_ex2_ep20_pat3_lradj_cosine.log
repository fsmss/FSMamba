/home/ubuntu/fsm_file/FSMamba/model/__init__.py
Args in experiment:
Namespace(is_training=1, model_id='exchange_rate_96_192', model='FsmMamba', data='custom', root_path='../../dataset/exchange_rate/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', pe_type='no', lradj='cosine', d_state=16, d_conv=4, expand=2, conv_bias=True, bias=True, dt_rank=32, dt_scale=1.0, dt_init='random', dt_max=0.1, dt_init_floor=0.0001, pscan=False, batch_size=64, patience=3, learning_rate=0.0001, e_layers=2, dropout=0.1, train_epochs=20, d_model=256, enc_in=8, dec_in=8, c_out=8, d_ff=102, seq_len=96, label_len=48, pred_len=192, n_heads=8, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, des='Exp', loss='MSE', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='4,5,6,7', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, i_or_cos=0, base=0, sigma=1, partial_start_index=0)
Number of GPUs available: 1
Use GPU: cuda:0
Total number of parameters: 2355202
>>>>>>>start training : exchange_rate_96_192_FsmMamba_custom_M_ft96_sl48_ll192_pl256_dm8_nh2_el1_dl102_df1_fctimeF_ebTrue_dtExp_projection_0_0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5024
val 569
test 1326
Epoch: 1 cost time: 4.278649806976318
Epoch: 1, Steps: 78 | Train Loss: 0.2806884 Vali Loss: 0.2284255 Test Loss: 0.1835592
Validation loss decreased (inf --> 0.228425).  Saving model ...
Updating learning rate to 9.938441702975689e-05
Epoch: 2 cost time: 3.4219000339508057
Epoch: 2, Steps: 78 | Train Loss: 0.2537648 Vali Loss: 0.2175150 Test Loss: 0.1785808
Validation loss decreased (0.228425 --> 0.217515).  Saving model ...
Updating learning rate to 9.755282581475769e-05
Epoch: 3 cost time: 4.087595701217651
Epoch: 3, Steps: 78 | Train Loss: 0.2430538 Vali Loss: 0.2197064 Test Loss: 0.1847437
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.45503262094184e-05
Epoch: 4 cost time: 3.690089702606201
Epoch: 4, Steps: 78 | Train Loss: 0.2324347 Vali Loss: 0.2383369 Test Loss: 0.1870879
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.045084971874738e-05
Epoch: 5 cost time: 3.8219892978668213
Epoch: 5, Steps: 78 | Train Loss: 0.2207968 Vali Loss: 0.2367826 Test Loss: 0.2040068
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : exchange_rate_96_192_FsmMamba_custom_M_ft96_sl48_ll192_pl256_dm8_nh2_el1_dl102_df1_fctimeF_ebTrue_dtExp_projection_0_0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
test shape: (1326, 1, 192, 8) (1326, 1, 192, 8)
test shape: (1326, 192, 8) (1326, 192, 8)
mse:0.17618080565929413, mae:0.2990077178478241,rse:0.3250749707221985
