/home/ubuntu/fsm_file/FSMamba/model/__init__.py
Args in experiment:
Namespace(is_training=1, model_id='exchange_rate_96_336', model='FsmMamba', data='custom', root_path='../../dataset/exchange_rate/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', pe_type='sincos', lradj='cosine', d_state=16, d_conv=4, expand=2, conv_bias=True, bias=True, dt_rank=32, dt_scale=1.0, dt_init='random', dt_max=0.1, dt_init_floor=0.0001, pscan=False, batch_size=64, patience=3, learning_rate=0.0002, e_layers=2, dropout=0.1, train_epochs=20, d_model=256, enc_in=8, dec_in=8, c_out=8, d_ff=102, seq_len=96, label_len=48, pred_len=336, n_heads=8, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, des='Exp', loss='MSE', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='4,5,6,7', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, i_or_cos=0, base=0, sigma=1, partial_start_index=0)
Number of GPUs available: 1
Use GPU: cuda:0
Total number of parameters: 2392210
>>>>>>>start training : exchange_rate_96_336_FsmMamba_custom_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl102_df1_fctimeF_ebTrue_dtExp_projection_0_0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4880
val 425
test 1182
Epoch: 1 cost time: 4.930794715881348
Epoch: 1, Steps: 76 | Train Loss: 0.4476266 Vali Loss: 0.3761172 Test Loss: 0.3282892
Validation loss decreased (inf --> 0.376117).  Saving model ...
Updating learning rate to 0.00019876883405951377
Epoch: 2 cost time: 3.7791318893432617
Epoch: 2, Steps: 76 | Train Loss: 0.4183853 Vali Loss: 0.3829862 Test Loss: 0.3351125
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00019510565162951537
Epoch: 3 cost time: 3.8043768405914307
Epoch: 3, Steps: 76 | Train Loss: 0.3859134 Vali Loss: 0.4025140 Test Loss: 0.3717661
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001891006524188368
Epoch: 4 cost time: 3.6803863048553467
Epoch: 4, Steps: 76 | Train Loss: 0.3404314 Vali Loss: 0.3960885 Test Loss: 0.4151946
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : exchange_rate_96_336_FsmMamba_custom_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl102_df1_fctimeF_ebTrue_dtExp_projection_0_0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1182
test shape: (1182, 1, 336, 8) (1182, 1, 336, 8)
test shape: (1182, 336, 8) (1182, 336, 8)
mse:0.32828935980796814, mae:0.415172815322876,rse:0.44510138034820557
