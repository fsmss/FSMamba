/home/ubuntu/fsm_file/FSMamba/model/__init__.py
Args in experiment:
Namespace(is_training=1, model_id='weather_96_720', model='FsmMamba', data='custom', root_path='../../dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', pe_type='no', lradj='cosine', d_state=16, d_conv=4, expand=2, conv_bias=True, bias=True, dt_rank=32, dt_scale=1.0, dt_init='random', dt_max=0.1, dt_init_floor=0.0001, pscan=False, batch_size=64, patience=3, learning_rate=0.0001, e_layers=2, dropout=0.2, train_epochs=20, d_model=512, enc_in=21, dec_in=21, c_out=21, d_ff=512, seq_len=96, label_len=48, pred_len=720, n_heads=8, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, des='Exp', loss='MSE', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='4,5,6,7', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, i_or_cos=0, base=0, sigma=1, partial_start_index=0)
Number of GPUs available: 1
Use GPU: cuda:0
Total number of parameters: 9362298
>>>>>>>start training : weather_96_720_FsmMamba_custom_M_ft96_sl48_ll720_pl512_dm8_nh2_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0_0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36072
val 4551
test 9820
	iters: 100, epoch: 1 | loss: 0.8039004
	speed: 0.0613s/iter; left time: 684.5331s
	iters: 200, epoch: 1 | loss: 0.6183988
	speed: 0.0487s/iter; left time: 538.8193s
	iters: 300, epoch: 1 | loss: 0.5545620
	speed: 0.0520s/iter; left time: 570.3036s
	iters: 400, epoch: 1 | loss: 0.6613808
	speed: 0.0507s/iter; left time: 551.1401s
	iters: 500, epoch: 1 | loss: 0.5616130
	speed: 0.0513s/iter; left time: 551.7371s
Epoch: 1 cost time: 29.480890035629272
Epoch: 1, Steps: 563 | Train Loss: 0.7084229 Vali Loss: 0.6970899 Test Loss: 0.3510544
Validation loss decreased (inf --> 0.697090).  Saving model ...
Updating learning rate to 9.938441702975689e-05
	iters: 100, epoch: 2 | loss: 0.6508438
	speed: 1.0628s/iter; left time: 11263.3646s
	iters: 200, epoch: 2 | loss: 0.6777900
	speed: 0.0587s/iter; left time: 616.6740s
	iters: 300, epoch: 2 | loss: 0.5440056
	speed: 0.0583s/iter; left time: 605.7759s
	iters: 400, epoch: 2 | loss: 0.6936961
	speed: 0.0592s/iter; left time: 609.1679s
	iters: 500, epoch: 2 | loss: 0.6329099
	speed: 0.0592s/iter; left time: 603.6134s
Epoch: 2 cost time: 32.82621169090271
Epoch: 2, Steps: 563 | Train Loss: 0.6405401 Vali Loss: 0.6864613 Test Loss: 0.3508050
Validation loss decreased (0.697090 --> 0.686461).  Saving model ...
Updating learning rate to 9.755282581475769e-05
	iters: 100, epoch: 3 | loss: 0.6347455
	speed: 1.0896s/iter; left time: 10934.4951s
	iters: 200, epoch: 3 | loss: 0.6817734
	speed: 0.0502s/iter; left time: 498.9943s
	iters: 300, epoch: 3 | loss: 0.6737815
	speed: 0.0508s/iter; left time: 499.4067s
	iters: 400, epoch: 3 | loss: 0.6996923
	speed: 0.0503s/iter; left time: 489.7359s
	iters: 500, epoch: 3 | loss: 0.7518937
	speed: 0.0509s/iter; left time: 490.1265s
Epoch: 3 cost time: 28.67964243888855
Epoch: 3, Steps: 563 | Train Loss: 0.6145525 Vali Loss: 0.6792182 Test Loss: 0.3504635
Validation loss decreased (0.686461 --> 0.679218).  Saving model ...
Updating learning rate to 9.45503262094184e-05
	iters: 100, epoch: 4 | loss: 0.6760425
	speed: 0.9708s/iter; left time: 9195.6230s
	iters: 200, epoch: 4 | loss: 0.7393366
	speed: 0.0501s/iter; left time: 469.4242s
	iters: 300, epoch: 4 | loss: 0.5702395
	speed: 0.0480s/iter; left time: 444.5986s
	iters: 400, epoch: 4 | loss: 0.4567319
	speed: 0.0499s/iter; left time: 457.9581s
	iters: 500, epoch: 4 | loss: 0.6522669
	speed: 0.0492s/iter; left time: 446.3052s
Epoch: 4 cost time: 27.988311767578125
Epoch: 4, Steps: 563 | Train Loss: 0.5898122 Vali Loss: 0.6901520 Test Loss: 0.3574606
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.045084971874738e-05
	iters: 100, epoch: 5 | loss: 0.6965069
	speed: 1.1143s/iter; left time: 9927.2288s
	iters: 200, epoch: 5 | loss: 0.4650560
	speed: 0.0580s/iter; left time: 511.1095s
	iters: 300, epoch: 5 | loss: 0.5321730
	speed: 0.0589s/iter; left time: 512.5326s
	iters: 400, epoch: 5 | loss: 0.5328074
	speed: 0.0583s/iter; left time: 501.9635s
	iters: 500, epoch: 5 | loss: 0.5299557
	speed: 0.0593s/iter; left time: 504.8092s
Epoch: 5 cost time: 32.77491593360901
Epoch: 5, Steps: 563 | Train Loss: 0.5605129 Vali Loss: 0.7031940 Test Loss: 0.3673758
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.535533905932738e-05
	iters: 100, epoch: 6 | loss: 0.5520926
	speed: 1.0209s/iter; left time: 8520.1919s
	iters: 200, epoch: 6 | loss: 0.6716778
	speed: 0.0488s/iter; left time: 402.6371s
	iters: 300, epoch: 6 | loss: 0.4887915
	speed: 0.0486s/iter; left time: 396.1803s
	iters: 400, epoch: 6 | loss: 0.6448679
	speed: 0.0485s/iter; left time: 390.2624s
	iters: 500, epoch: 6 | loss: 0.5502045
	speed: 0.0488s/iter; left time: 387.9894s
Epoch: 6 cost time: 27.32407021522522
Epoch: 6, Steps: 563 | Train Loss: 0.5300461 Vali Loss: 0.7181953 Test Loss: 0.3800906
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : weather_96_720_FsmMamba_custom_M_ft96_sl48_ll720_pl512_dm8_nh2_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0_0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (9820, 1, 720, 21) (9820, 1, 720, 21)
test shape: (9820, 720, 21) (9820, 720, 21)
mse:0.35046350955963135, mae:0.34759989380836487,rse:0.7790287137031555
