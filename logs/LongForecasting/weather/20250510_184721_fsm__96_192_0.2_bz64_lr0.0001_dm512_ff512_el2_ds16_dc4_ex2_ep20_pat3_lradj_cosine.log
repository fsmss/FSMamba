/home/ubuntu/fsm_file/FSMamba/model/__init__.py
Args in experiment:
Namespace(is_training=1, model_id='weather_96_192', model='FsmMamba', data='custom', root_path='../../dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', pe_type='no', lradj='cosine', d_state=16, d_conv=4, expand=2, conv_bias=True, bias=True, dt_rank=32, dt_scale=1.0, dt_init='random', dt_max=0.1, dt_init_floor=0.0001, pscan=False, batch_size=64, patience=3, learning_rate=0.0001, e_layers=2, dropout=0.2, train_epochs=20, d_model=512, enc_in=21, dec_in=21, c_out=21, d_ff=512, seq_len=96, label_len=48, pred_len=192, n_heads=8, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, des='Exp', loss='MSE', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='4,5,6,7', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, i_or_cos=0, base=0, sigma=1, partial_start_index=0)
Number of GPUs available: 1
Use GPU: cuda:0
Total number of parameters: 9091434
>>>>>>>start training : weather_96_192_FsmMamba_custom_M_ft96_sl48_ll192_pl512_dm8_nh2_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0_0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36600
val 5079
test 10348
	iters: 100, epoch: 1 | loss: 0.8021702
	speed: 0.0642s/iter; left time: 727.2835s
	iters: 200, epoch: 1 | loss: 0.6771858
	speed: 0.0542s/iter; left time: 608.6800s
	iters: 300, epoch: 1 | loss: 0.6222361
	speed: 0.0533s/iter; left time: 592.8198s
	iters: 400, epoch: 1 | loss: 0.3646318
	speed: 0.0548s/iter; left time: 603.9794s
	iters: 500, epoch: 1 | loss: 0.6224058
	speed: 0.0564s/iter; left time: 615.9326s
Epoch: 1 cost time: 32.187713384628296
Epoch: 1, Steps: 571 | Train Loss: 0.5535554 Vali Loss: 0.5046498 Test Loss: 0.2269748
Validation loss decreased (inf --> 0.504650).  Saving model ...
Updating learning rate to 9.938441702975689e-05
	iters: 100, epoch: 2 | loss: 0.4596960
	speed: 1.0386s/iter; left time: 11165.4293s
	iters: 200, epoch: 2 | loss: 0.6456848
	speed: 0.0484s/iter; left time: 515.1071s
	iters: 300, epoch: 2 | loss: 0.5942653
	speed: 0.0474s/iter; left time: 499.9237s
	iters: 400, epoch: 2 | loss: 0.9056199
	speed: 0.0460s/iter; left time: 481.0053s
	iters: 500, epoch: 2 | loss: 0.6067992
	speed: 0.0466s/iter; left time: 482.2061s
Epoch: 2 cost time: 26.85120677947998
Epoch: 2, Steps: 571 | Train Loss: 0.4882723 Vali Loss: 0.4768910 Test Loss: 0.2158770
Validation loss decreased (0.504650 --> 0.476891).  Saving model ...
Updating learning rate to 9.755282581475769e-05
	iters: 100, epoch: 3 | loss: 0.3966587
	speed: 1.0015s/iter; left time: 10194.2813s
	iters: 200, epoch: 3 | loss: 0.2880802
	speed: 0.0562s/iter; left time: 566.0279s
	iters: 300, epoch: 3 | loss: 0.5910720
	speed: 0.0580s/iter; left time: 579.2235s
	iters: 400, epoch: 3 | loss: 0.3159376
	speed: 0.0551s/iter; left time: 543.8915s
	iters: 500, epoch: 3 | loss: 0.3230324
	speed: 0.0542s/iter; left time: 529.8815s
Epoch: 3 cost time: 32.22102451324463
Epoch: 3, Steps: 571 | Train Loss: 0.4656950 Vali Loss: 0.4722951 Test Loss: 0.2103584
Validation loss decreased (0.476891 --> 0.472295).  Saving model ...
Updating learning rate to 9.45503262094184e-05
	iters: 100, epoch: 4 | loss: 0.8228024
	speed: 1.1585s/iter; left time: 11130.9013s
	iters: 200, epoch: 4 | loss: 0.3935933
	speed: 0.0553s/iter; left time: 526.0983s
	iters: 300, epoch: 4 | loss: 0.4121378
	speed: 0.0553s/iter; left time: 519.9240s
	iters: 400, epoch: 4 | loss: 0.3325134
	speed: 0.0538s/iter; left time: 500.6957s
	iters: 500, epoch: 4 | loss: 0.3065660
	speed: 0.0529s/iter; left time: 486.8039s
Epoch: 4 cost time: 30.70388150215149
Epoch: 4, Steps: 571 | Train Loss: 0.4458201 Vali Loss: 0.4723561 Test Loss: 0.2127517
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.045084971874738e-05
	iters: 100, epoch: 5 | loss: 0.3235675
	speed: 0.9930s/iter; left time: 8973.7168s
	iters: 200, epoch: 5 | loss: 0.3968920
	speed: 0.0459s/iter; left time: 410.5209s
	iters: 300, epoch: 5 | loss: 0.2979695
	speed: 0.0478s/iter; left time: 422.6594s
	iters: 400, epoch: 5 | loss: 0.5651311
	speed: 0.0457s/iter; left time: 399.1735s
	iters: 500, epoch: 5 | loss: 0.3159892
	speed: 0.0495s/iter; left time: 427.2912s
Epoch: 5 cost time: 27.10235571861267
Epoch: 5, Steps: 571 | Train Loss: 0.4242107 Vali Loss: 0.4800295 Test Loss: 0.2149793
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.535533905932738e-05
	iters: 100, epoch: 6 | loss: 0.2749502
	speed: 1.0885s/iter; left time: 9215.0931s
	iters: 200, epoch: 6 | loss: 0.3744708
	speed: 0.0574s/iter; left time: 480.1251s
	iters: 300, epoch: 6 | loss: 0.3532737
	speed: 0.0580s/iter; left time: 479.5569s
	iters: 400, epoch: 6 | loss: 0.4816290
	speed: 0.0572s/iter; left time: 466.9163s
	iters: 500, epoch: 6 | loss: 0.4702669
	speed: 0.0551s/iter; left time: 444.2501s
Epoch: 6 cost time: 32.699965953826904
Epoch: 6, Steps: 571 | Train Loss: 0.4017679 Vali Loss: 0.4878715 Test Loss: 0.2210520
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : weather_96_192_FsmMamba_custom_M_ft96_sl48_ll192_pl512_dm8_nh2_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0_0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
test shape: (10348, 1, 192, 21) (10348, 1, 192, 21)
test shape: (10348, 192, 21) (10348, 192, 21)
mse:0.210358127951622, mae:0.252103328704834,rse:0.6037369966506958
