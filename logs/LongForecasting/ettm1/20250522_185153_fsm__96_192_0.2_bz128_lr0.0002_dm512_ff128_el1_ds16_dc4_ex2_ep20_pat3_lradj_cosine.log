/home/ubuntu/fsm_file/FSMamba/model/__init__.py
Args in experiment:
Namespace(is_training=1, model_id='ETTm1_96_192', model='FsmMamba', data='ETTm1', root_path='../../dataset/ETT-small/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', pe_type='sincos', lradj='cosine', d_state=16, d_conv=4, expand=2, conv_bias=True, bias=True, dt_rank=32, dt_scale=1.0, dt_init='random', dt_max=0.1, dt_init_floor=0.0001, pscan=False, batch_size=128, patience=3, learning_rate=0.0002, e_layers=1, dropout=0.2, train_epochs=20, d_model=512, enc_in=7, dec_in=7, c_out=7, d_ff=128, seq_len=96, label_len=48, pred_len=192, n_heads=8, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, des='Exp', loss='MSE', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='4,5,6,7', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, i_or_cos=0, base=0, sigma=1, partial_start_index=0)
Number of GPUs available: 1
Use GPU: cuda:0
Total number of parameters: 4617949
>>>>>>>start training : ETTm1_96_192_FsmMamba_ETTm1_M_ft96_sl48_ll192_pl512_dm8_nh1_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0_0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3503330
	speed: 0.0511s/iter; left time: 267.7342s
	iters: 200, epoch: 1 | loss: 0.3343233
	speed: 0.0412s/iter; left time: 211.7036s
Epoch: 1 cost time: 12.031530618667603
Epoch: 1, Steps: 267 | Train Loss: 0.3467939 Vali Loss: 0.5097989 Test Loss: 0.3669510
Validation loss decreased (inf --> 0.509799).  Saving model ...
Updating learning rate to 0.00019876883405951377
	iters: 100, epoch: 2 | loss: 0.3339058
	speed: 0.8271s/iter; left time: 4113.9996s
	iters: 200, epoch: 2 | loss: 0.3084271
	speed: 0.0415s/iter; left time: 202.3326s
Epoch: 2 cost time: 11.062630891799927
Epoch: 2, Steps: 267 | Train Loss: 0.3066276 Vali Loss: 0.5050066 Test Loss: 0.3680936
Validation loss decreased (0.509799 --> 0.505007).  Saving model ...
Updating learning rate to 0.00019510565162951537
	iters: 100, epoch: 3 | loss: 0.3178419
	speed: 0.9118s/iter; left time: 4292.0744s
	iters: 200, epoch: 3 | loss: 0.2760910
	speed: 0.0426s/iter; left time: 196.0406s
Epoch: 3 cost time: 11.382967948913574
Epoch: 3, Steps: 267 | Train Loss: 0.2881437 Vali Loss: 0.5192029 Test Loss: 0.3767424
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001891006524188368
	iters: 100, epoch: 4 | loss: 0.3161300
	speed: 0.8171s/iter; left time: 3628.0746s
	iters: 200, epoch: 4 | loss: 0.2548723
	speed: 0.0415s/iter; left time: 179.9712s
Epoch: 4 cost time: 11.12029242515564
Epoch: 4, Steps: 267 | Train Loss: 0.2682822 Vali Loss: 0.5184838 Test Loss: 0.3888948
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018090169943749476
	iters: 100, epoch: 5 | loss: 0.2553092
	speed: 0.9198s/iter; left time: 3838.5067s
	iters: 200, epoch: 5 | loss: 0.2414204
	speed: 0.0427s/iter; left time: 173.7543s
Epoch: 5 cost time: 11.290719270706177
Epoch: 5, Steps: 267 | Train Loss: 0.2459385 Vali Loss: 0.5237817 Test Loss: 0.4241691
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_96_192_FsmMamba_ETTm1_M_ft96_sl48_ll192_pl512_dm8_nh1_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0_0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (11329, 1, 192, 7) (11329, 1, 192, 7)
test shape: (11329, 192, 7) (11329, 192, 7)
mse:0.3680937588214874, mae:0.3851509988307953,rse:0.577538251876831
